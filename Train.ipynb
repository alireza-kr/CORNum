{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w9_WLSuECzIm",
        "KakzNaLqDI4L",
        "ydb2rEb7zCar",
        "CuJc9wMKdmZa",
        "4_JMxfAaCAEo",
        "ip763Jv3CNda",
        "Un52mQ2ZGwFd",
        "xFB_zu1aGz7k",
        "LvZEguPLG4gE",
        "9hKUFdM7mD0u",
        "c8zZ3TM8mGKS",
        "GfUZkx0vVNhF",
        "36aCRwOOprV_",
        "GMIJRg5np4iD",
        "LgLST002qhhA",
        "ffD3HEGJrkWl",
        "QamUAqwirppL",
        "0hw2RN4hrv6J"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CORnet-Z"
      ],
      "metadata": {
        "id": "CuJc9wMKdmZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class ZipDataset(Dataset):\n",
        "    def __init__(self, zip_path, transform=None):\n",
        "        self.zip_path = zip_path\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        with zipfile.ZipFile(self.zip_path, 'r') as zip:\n",
        "            for file in zip.namelist():\n",
        "                if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    class_name = file.split('/')[1]  # Assuming the class name is the folder name\n",
        "                    self.samples.append((file, int(class_name)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, class_index = self.samples[idx]\n",
        "        with zipfile.ZipFile(self.zip_path, 'r') as zip:\n",
        "            with zip.open(file_path) as file:\n",
        "                image = Image.open(file)\n",
        "                image = image.convert('RGB')\n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "                return image, torch.tensor(class_index, dtype=torch.long)"
      ],
      "metadata": {
        "id": "hootm5rLknys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "4_JMxfAaCAEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from functools import reduce\n",
        "from cornet.extend_cornet_z import ExtendedCORnet\n",
        "\n",
        "seed = 0\n",
        "pl.seed_everything(seed)\n",
        "\n",
        "# -------------------------------\n",
        "# Parameters\n",
        "# -------------------------------\n",
        "\n",
        "# ESOS: 5\n",
        "# Testolin: 10\n",
        "n_max = 5 # max number of dots\n",
        "\n",
        "# -------------------------------\n",
        "# Paths where to load/save data\n",
        "# -------------------------------\n",
        "\n",
        "# path where model are saved\n",
        "model_path = project_path+'/result/model/cornetz_sgd'\n",
        "os.makedirs(f'{model_path}', exist_ok=True)\n",
        "# path where log of training are saved\n",
        "log_path = project_path+'/result/log/train'\n",
        "os.makedirs(f'{log_path}', exist_ok=True)\n",
        "# path containing the dataset\n",
        "train_path = project_path+'/images/ESOS/train'\n",
        "#train_path = project_path+'/images/Testolin_DeWind/train'\n",
        "#train_path = project_path+'/images/Testolin_Natural/train'\n",
        "#train_path = project_path+'/images/Testolin_ISA2/train'\n",
        "\n",
        "# -------------------------------\n",
        "# Training dataset\n",
        "# -------------------------------\n",
        "\n",
        "# Write transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(300, 300)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "])\n",
        "\n",
        "#train_data = ZipDataset(train_path, transform=data_transform)\n",
        "train_data = datasets.ImageFolder(root=train_path, # target folder of images\n",
        "                                  transform=data_transform, # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size = 32, shuffle = True, num_workers = 4, pin_memory = True)\n",
        "\n",
        "# -------------------------------\n",
        "# Initializing model\n",
        "# -------------------------------\n",
        "\n",
        "model  = ExtendedCORnet(out_features = n_max, lr = 1e-3, optimizer = 'sgd')\n",
        "\n",
        "# -------------------------------\n",
        "# Saving model\n",
        "# -------------------------------\n",
        "\n",
        "# saving initial model\n",
        "torch.save({\n",
        "\t\"epoch\": -1,\n",
        "\t\"global_step\": 0,\n",
        "\t\"pytorch-lightning_version\": pl.__version__,\n",
        "\t\"state_dict\": model.state_dict()\n",
        "}, f'{model_path}/epoch-1.ckpt')\n",
        "# using checkpoint to save models after each epoch\n",
        "checkpoint = pl.callbacks.ModelCheckpoint(dirpath = model_path, filename = 'epoch{epoch:02d}', auto_insert_metric_name = False, save_on_train_epoch_end = True, save_top_k = -1)\n",
        "# saving gpu stats\n",
        "gpu_stats = pl.callbacks.DeviceStatsMonitor()\n",
        "\n",
        "# -------------------------------\n",
        "# Training model\n",
        "# -------------------------------\n",
        "\n",
        "trainer = pl.Trainer(default_root_dir = log_path, callbacks = [gpu_stats, checkpoint], deterministic = True, accelerator = 'gpu', devices = 1, strategy = 'auto', num_nodes = 1, max_epochs = 100)\n",
        "#trainer = pl.Trainer(default_root_dir = log_path, callbacks = [gpu_stats, checkpoint], deterministic = True, accelerator = 'gpu', devices = 4, strategy = 'dpp', num_nodes = 1, max_epochs = 100)\n",
        "trainer.fit(model, train_loader)"
      ],
      "metadata": {
        "id": "TV-U_scIknQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model"
      ],
      "metadata": {
        "id": "ip763Jv3CNda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os, psutil\n",
        "process = psutil.Process(os.getpid())\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
        "from humanfriendly import format_size\n",
        "from functools import reduce\n",
        "from cornet.extend_cornet_z import ExtendedCORnet\n",
        "\n",
        "def main(args):\n",
        "\n",
        "    seed = 0\n",
        "    pl.seed_everything(seed)\n",
        "\n",
        "    # -------------------------------\n",
        "    # Parameters\n",
        "    # -------------------------------\n",
        "\n",
        "    n_max = 5\n",
        "\n",
        "    # -------------------------------\n",
        "    # Paths where to load/save data\n",
        "    # -------------------------------\n",
        "\n",
        "    # path where activities are saved\n",
        "    activity_path = project_path+'/Script/result/activity/cornetz_sgd'\n",
        "    os.makedirs(f'{activity_path}', exist_ok=True)\n",
        "    # path where accuracies are saved\n",
        "    accuracy_path = project_path+'/Script/result/accuracy/cornetz_sgd'\n",
        "    os.makedirs(f'{accuracy_path}', exist_ok=True)\n",
        "    # path where log of training are saved\n",
        "    log_path = project_path+'/Script/result/log/test'\n",
        "    os.makedirs(f'{log_path}', exist_ok=True)\n",
        "    # path containing the dataset\n",
        "    test_path = project_path+'/Script/images/Testolin_DeWind/test'\n",
        "    # path containing the model\n",
        "    model_path = project_path+'/Script/result/model/cornetz_sgd'\n",
        "\n",
        "    # -------------------------------\n",
        "    # Test dataset\n",
        "    # -------------------------------\n",
        "\n",
        "    # Write transform for image\n",
        "    data_transform = transforms.Compose([\n",
        "        # Resize the images to 64x64\n",
        "        transforms.Resize(size=(64, 64)),\n",
        "        # Flip the images randomly on the horizontal\n",
        "        transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
        "        # Turn the image into a torch.Tensor\n",
        "        transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "    ])\n",
        "\n",
        "    test_data = datasets.ImageFolder(root=test_path, transform=data_transform)\n",
        "    test_loader = DataLoader(dataset=test_data, batch_size = 32, shuffle = False, num_workers = 4, pin_memory = True)\n",
        "\n",
        "    # -------------------------------\n",
        "    # Saving model\n",
        "    # -------------------------------\n",
        "\n",
        "    def hook_output(m, i, o):\n",
        "        activity[m].append(o.cpu())\n",
        "\n",
        "    class LabelConditionCallback(Callback):\n",
        "        def on_test_batch_start(self, trainer, pl_module, batch, batch_idx, dataloader_idx=0):\n",
        "            label.append(batch[1].cpu())\n",
        "            condition.append(batch[2].cpu())\n",
        "            param.append(batch[3].cpu())\n",
        "\n",
        "    epochs = args.epochs\n",
        "    accuracy = np.zeros(len(epochs))\n",
        "    trainer = pl.Trainer(default_root_dir=log_path, callbacks = [LabelConditionCallback()], deterministic=True, devices=\"auto\", accelerator=\"auto\")\n",
        "    model  = ExtendedCORnet(out_features = n_max)\n",
        "\n",
        "    modules = [getattr(model.model.module, m).output for m in [\"V1\", \"V2\", \"V4\", \"IT\", \"decoder\"]]\n",
        "    module_names = {getattr(model.model.module, m).output:m for m in [\"V1\", \"V2\", \"V4\", \"IT\", \"decoder\"]}\n",
        "    times = {getattr(model.model.module, m).output:getattr(model.model.module, m).times if hasattr(getattr(model.model.module, m), \"times\") else 1 for m in [\"V1\", \"V2\", \"V4\", \"IT\", \"decoder\"]}\n",
        "    for m in modules:\n",
        "        m.register_forward_hook(hook_output)\n",
        "\n",
        "    # -------------------------------\n",
        "    # Testing model\n",
        "    # -------------------------------\n",
        "\n",
        "    for i, epoch in enumerate(epochs):\n",
        "        os.makedirs(f'{activity_path}/epoch{epoch:02}', exist_ok=True)\n",
        "        checkpoint = torch.load(f'{model_path}/epoch{epoch:02}.ckpt')\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        activity = {}\n",
        "        label = []\n",
        "        condition = []\n",
        "        param = []\n",
        "        for m in modules:\n",
        "            activity[m]= []\n",
        "        metrics, = trainer.test(model, test_loader)\n",
        "        label = torch.cat(label).cpu().numpy()[:, None]\n",
        "        if not os.path.exists(f'{activity_path}/epoch{epoch:02}/label.npz'):\n",
        "            np.savez_compressed(f'{activity_path}/epoch{epoch:02}/label.npz', label = label)\n",
        "            print(f'label at epoch {epoch} saved in .npz ({format_size(process.memory_info().rss)})')\n",
        "        else:\n",
        "            print(f'label at epoch {epoch} already saved in .npz ({format_size(process.memory_info().rss)})')\n",
        "        condition = torch.cat(condition).cpu().numpy()[:, None]\n",
        "        if not os.path.exists(f'{activity_path}/epoch{epoch:02}/condition.npz'):\n",
        "            np.savez_compressed(f'{activity_path}/epoch{epoch:02}/condition.npz', condition = condition)\n",
        "            print(f'condition at epoch {epoch} saved in .npz ({format_size(process.memory_info().rss)})')\n",
        "        else:\n",
        "            print(f'condition at epoch {epoch} already saved in .npz ({format_size(process.memory_info().rss)})')\n",
        "        param = torch.cat(param).cpu().numpy()[:, None]\n",
        "        if not os.path.exists(f'{activity_path}/epoch{epoch:02}/param.npz'):\n",
        "            np.savez_compressed(f'{activity_path}/epoch{epoch:02}/param.npz', param = param)\n",
        "            print(f'param at epoch {epoch} saved in .npz ({format_size(process.memory_info().rss)})')\n",
        "        else:\n",
        "            print(f'param at epoch {epoch} already saved in .npz ({format_size(process.memory_info().rss)})')\n",
        "        print(f'Test finished ({format_size(process.memory_info().rss)})')\n",
        "        accuracy[i] = metrics['test_acc_epoch']\n",
        "        for m in modules:\n",
        "            if not os.path.exists(f'{activity_path}/epoch{epoch:02}/{module_names[m]}.npz'):\n",
        "                print(f'starting saving {module_names[m]} at epoch {epoch} ({format_size(process.memory_info().rss)})')\n",
        "                tmp = torch.stack([torch.cat(activity[m][i::times[m]]) for i in range(times[m])], axis = 1).numpy()\n",
        "                print(f'tmp created ({format_size(process.memory_info().rss)})')\n",
        "                del activity[m]\n",
        "                print(f'activity[m] removed ({format_size(process.memory_info().rss)})')\n",
        "                print(module_names[m], tmp.shape)\n",
        "                data_dict = {}\n",
        "                data_dict[module_names[m]] = tmp\n",
        "                print(f'data_dict created ({format_size(process.memory_info().rss)})')\n",
        "                np.savez_compressed(f'{activity_path}/epoch{epoch:02}/{module_names[m]}.npz', **data_dict)\n",
        "                print(f'{module_names[m]} at epoch {epoch} saved in .npz ({format_size(process.memory_info().rss)})')\n",
        "                del tmp\n",
        "                del data_dict\n",
        "            else:\n",
        "                print(f'{module_names[m]} at epoch {epoch} already saved in .npz ({format_size(process.memory_info().rss)})')\n",
        "\n",
        "    epoch_accuracy = np.zeros(len(epochs), dtype = np.dtype([('epoch', np.int64, 1), ('accuracy', np.float64, 1)]))\n",
        "    epoch_accuracy['epoch'] = epochs\n",
        "    epoch_accuracy['accuracy'] = accuracy\n",
        "    os.makedirs(f'{accuracy_path}', exist_ok=True)\n",
        "    np.save(f'{accuracy_path}/epochs_{epochs}_accuracy.npy', epoch_accuracy)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description = 'Test models at different epochs')\n",
        "    parser.add_argument('--epochs', metavar = 'E', type = int, nargs = \"+\", help = 'list of epochs to test')\n",
        "    args = parser.parse_args()\n",
        "    main(args)"
      ],
      "metadata": {
        "id": "UTm2b_Fckq6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import pytorch_lightning as pl\n",
        "from functools import reduce\n",
        "from cornet.extend_cornet_z import ExtendedCORnet\n",
        "\n",
        "seed = 0\n",
        "pl.seed_everything(seed)\n",
        "\n",
        "# -------------------------------\n",
        "# Parameters\n",
        "# -------------------------------\n",
        "\n",
        "# ESOS: 5\n",
        "# Testolin: 10\n",
        "n_max = 10 # max number of dots\n",
        "\n",
        "# -------------------------------\n",
        "# Paths where to load/save data\n",
        "# -------------------------------\n",
        "\n",
        "# path containing the dataset\n",
        "#test_path = project_path+'/Script/images/ESOS/test'\n",
        "#test_path = project_path+'/Script/images/Testolin_DeWind/test'\n",
        "#test_path = project_path+'/Script/images/Testolin_Natural/test'\n",
        "test_path = project_path+'/Script/images/Testolin_ISA2/test'\n",
        "# path containing the model\n",
        "model_path = project_path+'/Script/result/model/cornetz_sgd'\n",
        "\n",
        "# -------------------------------\n",
        "# Test dataset\n",
        "# -------------------------------\n",
        "\n",
        "# Write transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(300, 300)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "])\n",
        "\n",
        "#test_data = ZipDataset(test_path, transform=data_transform)\n",
        "test_data = datasets.ImageFolder(root=test_path, transform=data_transform)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size = 32, shuffle = False, num_workers = 4, pin_memory = True)\n",
        "\n",
        "# -------------------------------\n",
        "# Initializing model\n",
        "# -------------------------------\n",
        "\n",
        "model  = ExtendedCORnet(out_features = n_max)\n",
        "\n",
        "checkpoint = torch.load(f'{model_path}/cornetz_testolin_isa2.ckpt')\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "trainer = pl.Trainer(deterministic=True, devices=\"auto\", accelerator=\"auto\")\n",
        "metrics, = trainer.test(model, test_loader)"
      ],
      "metadata": {
        "id": "IguRGs4Ozx7Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}