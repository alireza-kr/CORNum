# this script is generated by gemini 2.5 and then verified by the authors

import numpy as np
import os
import collections # For defaultdict
import itertools

# --- Configuration ---
base_path = './results/scorecam/DeWind_test_small_array' # Current directory, adjust if folders are elsewhere
folders = ['imagenet', 'dewind', 'untrained']
files_in_each_folder = ['6.npy', '7.npy']
layer_names = ['V1', 'V2', 'V4', 'IT'] # Corresponding to the 4 layers index 0-3

# Dictionary to hold the stacked and flattened data for each mode (folder)
# Key: folder name (e.g., 'imagenet'), Value: numpy array (num_total_images, num_layers, flattened_spatial)
mode_data_flattened = {}

print("--- Loading and Stacking Data ---")
for folder in folders:
    folder_path = os.path.join(base_path, folder)
    print(f"Processing folder: {folder_path}")

    # List to hold data from files within this folder before stacking
    data_list_for_folder = []

    for filename in files_in_each_folder:
        file_path = os.path.join(folder_path, filename)
        print(f"  Loading file: {file_path}")
        # Load the 4D array
        data = np.load(file_path)
        data_list_for_folder.append(data)


    # 1. Stack all images within the folder
    # Stacks along the first axis (axis=0), combining images from 6.npy and 7.npy
    stacked_data = np.concatenate(data_list_for_folder, axis=0)
    print(f"  Stacked data shape for {folder}: {stacked_data.shape}") # Should be (20, 4, 300, 300) if each file had 10 images

    # Flatten the spatial dimensions (300x300 -> 90000)
    num_total_images = stacked_data.shape[0]
    num_layers = stacked_data.shape[1]
    flattened_spatial_dim = stacked_data.shape[2] * stacked_data.shape[3]

    # Reshape to (num_total_images, num_layers, flattened_spatial_dim)
    flattened_data = stacked_data.reshape(num_total_images, num_layers, flattened_spatial_dim)
    print(f"  Flattened data shape for {folder}: {flattened_data.shape}") # Should be (20, 4, 90000)

    mode_data_flattened[folder] = flattened_data

print("\n--- Organizing Data for Comparison ---")

# Determine common dimensions from the first loaded mode
first_mode = folders[0]
num_total_images = mode_data_flattened[first_mode].shape[0]
num_layers = mode_data_flattened[first_mode].shape[1]
flattened_spatial_dim = mode_data_flattened[first_mode].shape[2] # Should be 90000

# Create the final organized structure
# Using nested defaultdict for convenience: comparison_data[image_index][layer_name] = {mode: data_vector}
comparison_data = collections.defaultdict(lambda: collections.defaultdict(dict))

# Populate the comparison structure
for img_idx in range(num_total_images):
    for layer_idx in range(num_layers):
        layer_name = layer_names[layer_idx] # Get the string name ('V1', 'V2', etc.)
        for mode in folders:
            # Extract the flattened heatmap vector for this specific image, layer, and mode
            heatmap_vector = mode_data_flattened[mode][img_idx, layer_idx, :]
            # Store it in the nested dictionary
            comparison_data[img_idx][layer_name][mode] = heatmap_vector

print("\n--- Data Organization Complete ---")
print(f"Total images processed: {num_total_images}")
print(f"Layers per image: {num_layers} ({', '.join(layer_names)})")
print(f"Spatial dimensions flattened to: {flattened_spatial_dim}")

# --- Example Usage ---
# How to access the data for comparison:

if num_total_images > 0 and num_layers > 0:
    example_img_idx = 0 # First image (index 0)
    example_layer_name = 'V4' # V4 layer

    print(f"\nExample: Accessing data for Image {example_img_idx}, Layer {example_layer_name}")

    if example_img_idx in comparison_data and example_layer_name in comparison_data[example_img_idx]:
        layer_comparison_data = comparison_data[example_img_idx][example_layer_name]

        for mode, heatmap_vector in layer_comparison_data.items():
            print(f"  Mode '{mode}':")
            print(f"    Data shape: {heatmap_vector.shape}") # Should be (90000,)
            # print(f"    First 5 values: {heatmap_vector[:5]}") # Print first few values as sample
            # You can now perform comparisons between these vectors, e.g., calculate correlations, distances, etc.
            # correlation = np.corrcoef(layer_comparison_data['imagenet'], layer_comparison_data['dewind'])[0, 1]
            # print(f"    Correlation between imagenet and dewind: {correlation:.4f}")
    else:
         print(f"  ERROR: Could not find data for Image {example_img_idx}, Layer {example_layer_name} in the organized structure.")

# You can also iterate through the structure:
# for img_idx, layers_data in comparison_data.items():
#     print(f"Image {img_idx}:")
#     for layer_name, modes_data in layers_data.items():
#         print(f"  Layer {layer_name}:")
#         # Access modes_data['imagenet'], modes_data['dewind'], modes_data['untrained']
#         # Example: print(f"    Imagenet data shape: {modes_data['imagenet'].shape}")

print("\n--- Applying Threshold (Top 75%) and Calculating Correlations ---")

# Percentage of values to keep (highest values)
percentile_to_keep_above = 75  # We keep values >= the 25th percentile

# Dictionary to store the *average* correlation among modes for each image, per layer (using thresholded data)
# layer_avg_correlations_thresh[layer_name] = [avg_corr_img0, avg_corr_img1, ...]
layer_avg_correlations_thresh = collections.defaultdict(list)

# Get all unique pairs of modes to compare
mode_pairs = list(itertools.combinations(folders, 2))

# Iterate through each image and layer
for img_idx in range(num_total_images):
    if img_idx not in comparison_data:
        print(f"Warning: Missing data for image index {img_idx}. Skipping.")
        continue

    for layer_name in layer_names:
        if layer_name not in comparison_data[img_idx]:
            print(f"Warning: Missing layer '{layer_name}' for image index {img_idx}. Skipping.")
            continue

        current_data = comparison_data[img_idx][layer_name]

        # Check if all modes are present for this image/layer
        if not all(mode in current_data for mode in folders):
            print(
                f"Warning: Missing mode data for image {img_idx}, layer {layer_name}. Skipping correlation calculation.")
            continue

        # --- Apply Thresholding ---
        thresholded_data = {}
        for mode in folders:
            original_vec = current_data[mode]
            if original_vec.size == 0:  # Handle empty vector case
                thresholded_data[mode] = original_vec  # Keep it empty
                continue

            # Find the threshold value (25th percentile)
            threshold_value = np.percentile(original_vec, percentile_to_keep_above)

            # Create the thresholded vector: keep values >= threshold, set others to 0
            # Using np.where for clarity: np.where(condition, value_if_true, value_if_false)
            thresholded_vec = np.where(original_vec >= threshold_value, original_vec, 0.0)

            # Handle edge case where threshold is 0 and all values are 0
            # If the threshold is 0, only values >= 0 are kept. If all original values were <= 0,
            # they might all become 0. This is usually fine.
            # An alternative check: if threshold_value == 0 and np.all(original_vec <= 0):
            #     thresholded_vec = np.zeros_like(original_vec)

            thresholded_data[mode] = thresholded_vec
        # --- End Thresholding ---

        # List to store the pairwise correlations for this specific image/layer (using thresholded data)
        pairwise_correlations_for_image_layer = []

        for mode1, mode2 in mode_pairs:
            # Use the thresholded vectors
            vec1 = thresholded_data[mode1]
            vec2 = thresholded_data[mode2]

            # Check vector sizes again in case of issues during thresholding
            if vec1.size == 0 or vec2.size == 0:
                correlation = np.nan
            # Check for constant vectors (zero standard deviation) AFTER thresholding
            elif np.std(vec1) == 0 or np.std(vec2) == 0:
                correlation = np.nan  # Use NaN for undefined correlation
                # print(f"  Info: Constant thresholded vector detected for image {img_idx}, layer {layer_name}, modes ({mode1}, {mode2}). Corr set to NaN.")
            else:
                # Calculate Pearson correlation coefficient on thresholded vectors
                correlation = np.corrcoef(vec1, vec2)[0, 1]
                if np.isnan(correlation):  # Check for NaN result from calculation itself
                    print(
                        f"  Warning: NaN correlation calculated for THRESHOLDED data img {img_idx}, layer {layer_name}, modes ({mode1}, {mode2}). Setting to NaN.")
                    correlation = np.nan  # Ensure it's NaN

            pairwise_correlations_for_image_layer.append(correlation)

        # Calculate the average of the pairwise correlations for this image/layer, ignoring NaNs
        average_correlation = np.nanmean(pairwise_correlations_for_image_layer)

        # Append the average correlation (from thresholded data) to the list for this layer
        layer_avg_correlations_thresh[layer_name].append(average_correlation)

print("\n--- Correlation Analysis Results (using Top 75% Thresholded Data) ---")

# Calculate and report mean and std dev for each layer, ignoring any NaNs
results_thresh = {}
for layer_name in layer_names:
    correlations = layer_avg_correlations_thresh[layer_name]
    if correlations:  # Check if the list is not empty
        mean_corr = np.nanmean(correlations)
        std_corr = np.nanstd(correlations)
        nan_count = np.isnan(correlations).sum()
        total_count = len(correlations)
        results_thresh[layer_name] = {'mean': mean_corr, 'std': std_corr, 'n': total_count - nan_count,
                                      'total': total_count}
        print(f"Layer: {layer_name}")
        print(f"  Mean Correlation (avg. across images): {mean_corr:.4f}")
        print(f"  Std Dev Correlation (avg. across images): {std_corr:.4f}")
        if nan_count > 0:
            print(f"  (Calculated using {total_count - nan_count}/{total_count} valid image correlations)")
    else:
        print(f"Layer: {layer_name} - No correlation data available.")
        results_thresh[layer_name] = {'mean': np.nan, 'std': np.nan, 'n': 0, 'total': 0}

print("\n--- Summary (Thresholded Data) ---")
print("Mean (Std Dev) of Average Pairwise Correlations Among Modes (Top 75% Values):")
for layer_name, res in results_thresh.items():
    print(f"- {layer_name:<4}: {res['mean']:.4f} ({res['std']:.4f})  [n={res['n']}/{res['total']}]")

